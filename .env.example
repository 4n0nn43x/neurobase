# Database Configuration (TimescaleDB/PostgreSQL)
# Format: postgresql://user:password@host:port/database?sslmode=require
DATABASE_URL=postgresql://tsdbadmin:your-password@your-service.tsdb.cloud.timescale.com:5432/tsdb?sslmode=require

# LLM Provider Configuration
# Choose one or more: openai, anthropic, ollama
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_TEMPERATURE=0.1
OPENAI_MAX_TOKENS=2000

# Anthropic Configuration
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_TEMPERATURE=0.1
ANTHROPIC_MAX_TOKENS=2000

# Ollama Configuration (local models)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_TEMPERATURE=0.1

# NeuroBase Configuration
NEUROBASE_MODE=interactive  # interactive, api, readonly
NEUROBASE_LOG_LEVEL=warn    # debug, info, warn, error (warn = interface propre, info = logs détaillés)
NEUROBASE_PORT=3000

# Feature Flags
ENABLE_LEARNING=true
ENABLE_OPTIMIZATION=true
ENABLE_SCHEMA_SUGGESTIONS=true
ENABLE_QUERY_CACHE=true

# Security
API_RATE_LIMIT=100          # requests per 15 minutes
READONLY_MODE=false          # set to true for production databases
MAX_QUERY_TIME=30000        # milliseconds

# Embeddings (for semantic search)
EMBEDDING_PROVIDER=openai   # openai, cohere, local
EMBEDDING_MODEL=text-embedding-3-small
COHERE_API_KEY=             # only if using cohere

# Logging
LOG_QUERIES=true
LOG_PERFORMANCE=true
LOG_FILE=logs/neurobase.log

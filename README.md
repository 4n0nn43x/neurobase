# NeuroBase ðŸ§ 

**An intelligent, self-learning conversational database built on Agentic Postgres**

NeuroBase transforms PostgreSQL into a cognitive system that understands natural language, automatically optimizes queries, and learns from every interaction. Built for the [Tiger Data Agentic Postgres Challenge](https://dev.to/devteam/join-the-agentic-postgres-challenge-with-tiger-data-3000-in-prizes-17ip).

---

## ðŸŽ¯ Vision

> "You don't speak SQL to your database anymore. Your database understands you and becomes smarter with every question."

NeuroBase is not just a natural language interface to SQLâ€”it's a **learning database system** that:

- ðŸ—£ï¸ **Understands natural language queries** in plain English
- âš¡ **Generates optimized SQL** automatically
- ðŸ§  **Learns from corrections** and improves over time
- ðŸ” **Optimizes performance** by analyzing query execution
- ðŸ’¾ **Remembers context** across conversations
- ðŸ¤– **Supports multiple LLM providers** (OpenAI, Anthropic, Ollama)

---

## ðŸ—ï¸ Architecture

NeuroBase uses a **multi-agent architecture** powered by Tiger Data's MCP (Model Context Protocol):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NeuroBase Core                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Linguistic  â”‚  â”‚  Optimizer   â”‚  â”‚   Memory     â”‚ â”‚
â”‚  â”‚    Agent     â”‚  â”‚    Agent     â”‚  â”‚   Agent      â”‚ â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚ â”‚
â”‚  â”‚ NL â†’ SQL     â”‚  â”‚ Performance  â”‚  â”‚ Learning     â”‚ â”‚
â”‚  â”‚ Translation  â”‚  â”‚ Analysis     â”‚  â”‚ Engine       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                  â”‚                  â”‚        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                            â”‚                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Agentic        â”‚
                    â”‚  Postgres       â”‚
                    â”‚  (Tiger Cloud)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agents

#### 1. **Linguistic Agent** ðŸ—£ï¸
- Translates natural language to SQL
- Uses schema introspection to understand table structures
- Supports multiple LLM backends (OpenAI GPT-4, Claude, Ollama)
- Handles ambiguous queries with clarifying questions

#### 2. **Optimizer Agent** âš¡
- Analyzes query execution plans (`EXPLAIN ANALYZE`)
- Suggests and applies index optimizations
- Rewrites queries for better performance
- Monitors query execution times

#### 3. **Memory Agent** ðŸ§ 
- Stores interaction history (NL query â†” SQL mapping)
- Creates embeddings for semantic search
- Learns from user corrections
- Builds contextual understanding over time

---

## ðŸš€ Features

### Core Capabilities

- âœ… **Natural Language Queries**: Ask questions in plain English
- âœ… **Multi-LLM Support**: OpenAI, Anthropic Claude, and Ollama (local models)
- âœ… **Automatic SQL Generation**: Context-aware SQL from natural language
- âœ… **Query Optimization**: Automatic performance tuning
- âœ… **Learning System**: Improves accuracy with each interaction
- âœ… **Schema Awareness**: Understands your database structure
- âœ… **Context Retention**: Remembers previous queries in conversation
- âœ… **Transparent Mode**: Shows generated SQL and execution plans
- âœ… **Error Recovery**: Learns from mistakes and corrections

### Advanced Features

- ðŸ”„ **Adaptive Schema Evolution**: Suggests materialized views for common queries
- ðŸ“Š **Performance Analytics**: Tracks and visualizes query performance
- ðŸ” **Safe Execution**: Read-only mode for production databases
- ðŸŽ¯ **Intent Recognition**: Understands user goals beyond literal queries
- ðŸ“ **Interaction History**: Full audit trail of all conversations

---

## ðŸ“‹ Prerequisites

- **Node.js** 18+ or **Python** 3.10+
- **Tiger Data Account** (free tier available)
- **Tiger CLI** installed
- At least one LLM provider:
  - OpenAI API key, OR
  - Anthropic API key, OR
  - Ollama running locally

---

## ðŸ”§ Installation

### 1. Install Tiger CLI

```bash
curl -fsSL https://cli.tigerdata.com | sh
tiger auth login
```

### 2. Clone and Install NeuroBase

```bash
git clone https://github.com/yourusername/neurobase.git
cd neurobase
npm install
# or for Python: pip install -r requirements.txt
```

### 3. Configure Environment

```bash
cp .env.example .env
```

Edit `.env` with your credentials:

```env
# Tiger Data Configuration
TIGER_SERVICE_ID=your-service-id

# LLM Provider (choose one or more)
LLM_PROVIDER=openai  # Options: openai, anthropic, ollama

# OpenAI Configuration
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4-turbo-preview

# Anthropic Configuration
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Ollama Configuration (local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# NeuroBase Configuration
NEUROBASE_MODE=interactive  # interactive, api, readonly
NEUROBASE_LOG_LEVEL=info
ENABLE_LEARNING=true
ENABLE_OPTIMIZATION=true
```

### 4. Initialize Database

```bash
npm run init
# This creates the necessary tables for memory/learning
```

---

## ðŸŽ® Usage

### Interactive CLI Mode

```bash
npm start
```

Example conversation:

```
NeuroBase> Show me the top 5 customers by total purchases this month

ðŸ§  Analyzing query...
ðŸ“ Generated SQL:
   SELECT c.name, SUM(o.total) as total_purchases
   FROM customers c
   JOIN orders o ON c.id = o.customer_id
   WHERE o.order_date >= date_trunc('month', current_date)
   GROUP BY c.name
   ORDER BY total_purchases DESC
   LIMIT 5;

âš¡ Execution time: 45ms

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ name         â”‚ total_purchases â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ John Smith   â”‚ $5,240.00       â”‚
â”‚ Alice Brown  â”‚ $4,890.00       â”‚
â”‚ Bob Johnson  â”‚ $3,750.00       â”‚
â”‚ Carol White  â”‚ $3,200.00       â”‚
â”‚ David Lee    â”‚ $2,980.00       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ’¡ Learned: "top N by total purchases" â†’ SUM() + GROUP BY + ORDER BY + LIMIT

NeuroBase> What about last month?

ðŸ§  Using context from previous query...
ðŸ“ Generated SQL:
   [Same query with adjusted date range]
...
```

### API Mode

```bash
npm run serve
```

```javascript
// Query the API
const response = await fetch('http://localhost:3000/api/query', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    query: "Show me products that are running low on stock",
    userId: "user123",
    includeExplanation: true
  })
});

const result = await response.json();
console.log(result.data);
```

### Programmatic Usage

```javascript
import { NeuroBase } from 'neurobase';

const nb = new NeuroBase({
  provider: 'openai',
  serviceId: 'your-service-id',
  enableLearning: true
});

const result = await nb.query(
  "Which products had the highest sales growth last quarter?"
);

console.log(result.data);
console.log(result.sql);
console.log(result.explanation);
```

---

## ðŸ§ª Examples

### Example 1: Simple Query

```
User: "How many users signed up today?"

NeuroBase generates:
SELECT COUNT(*) FROM users
WHERE created_at::date = CURRENT_DATE;
```

### Example 2: Complex Aggregation

```
User: "Show me average order value by product category for the last 6 months"

NeuroBase generates:
SELECT
  pc.name AS category,
  AVG(oi.price * oi.quantity) AS avg_order_value,
  COUNT(DISTINCT o.id) AS order_count
FROM product_categories pc
JOIN products p ON pc.id = p.category_id
JOIN order_items oi ON p.id = oi.product_id
JOIN orders o ON oi.order_id = o.id
WHERE o.created_at >= CURRENT_DATE - INTERVAL '6 months'
GROUP BY pc.name
ORDER BY avg_order_value DESC;
```

### Example 3: Learning from Corrections

```
User: "Show me inactive customers"

NeuroBase: [generates SQL with WHERE last_login < 30 days]

User: "No, I mean customers who haven't ordered in 90 days"

NeuroBase:
âœ… Correction learned! Updated definition:
   "inactive customers" â†’ no orders in 90 days

[Stores this mapping for future queries]
```

---

## ðŸ—ï¸ Project Structure

```
neurobase/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ linguistic.ts      # NL â†’ SQL translation
â”‚   â”‚   â”œâ”€â”€ optimizer.ts       # Query optimization
â”‚   â”‚   â””â”€â”€ memory.ts          # Learning & context
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ neurobase.ts       # Main orchestrator
â”‚   â”‚   â”œâ”€â”€ database.ts        # Tiger Cloud connection
â”‚   â”‚   â””â”€â”€ schema.ts          # Schema introspection
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â”œâ”€â”€ openai.ts      # OpenAI integration
â”‚   â”‚   â”‚   â”œâ”€â”€ anthropic.ts   # Claude integration
â”‚   â”‚   â”‚   â””â”€â”€ ollama.ts      # Ollama integration
â”‚   â”‚   â””â”€â”€ base.ts            # LLM provider interface
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”œâ”€â”€ cli.ts             # Interactive CLI
â”‚   â”‚   â””â”€â”€ api.ts             # REST API server
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.ts
â”‚       â”œâ”€â”€ validator.ts
â”‚       â””â”€â”€ embeddings.ts
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ ecommerce/             # E-commerce demo
â”‚   â”œâ”€â”€ analytics/             # Analytics demo
â”‚   â””â”€â”€ crm/                   # CRM demo
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md        # Detailed architecture
â”‚   â”œâ”€â”€ API.md                 # API documentation
â”‚   â”œâ”€â”€ DEPLOYMENT.md          # Deployment guide
â”‚   â””â”€â”€ CONTRIBUTING.md        # Contribution guidelines
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ init.sql               # Initial schema
â”‚   â””â”€â”€ seed.sql               # Sample data
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”œâ”€â”€ .env.example
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

---

## ðŸ§ª Running Tests

```bash
# Unit tests
npm test

# Integration tests
npm run test:integration

# E2E tests
npm run test:e2e

# All tests with coverage
npm run test:all
```

---

## ðŸ“Š Performance

NeuroBase is designed for performance:

- **Query Translation**: < 500ms (depends on LLM provider)
- **Local Ollama**: < 200ms for small models
- **Schema Caching**: Reduces introspection overhead
- **Connection Pooling**: Efficient database connections
- **Embedding Cache**: Fast semantic search for learned queries

---

## ðŸ›¡ï¸ Security

- **Read-only mode** for production databases
- **Parameterized queries** prevent SQL injection
- **API key encryption** at rest
- **Audit logging** for all queries
- **Rate limiting** on API endpoints

---

## ðŸ—ºï¸ Roadmap

### Phase 1: Core (Current)
- âœ… Multi-agent architecture
- âœ… Natural language to SQL
- âœ… Multi-LLM support
- âœ… Basic learning system

### Phase 2: Intelligence
- ðŸ”„ Advanced context retention
- ðŸ”„ Cross-query optimization
- ðŸ”„ Automatic materialized view suggestions
- ðŸ”„ Performance regression detection

### Phase 3: Ecosystem
- â³ Web UI dashboard
- â³ VS Code extension
- â³ Slack/Discord bot integration
- â³ Query templates marketplace

### Phase 4: Enterprise
- â³ Multi-tenant support
- â³ Role-based access control
- â³ Advanced analytics
- â³ Custom agent plugins

---

## ðŸ¤ Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](docs/CONTRIBUTING.md) for guidelines.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ðŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ðŸ™ Acknowledgments

- **Tiger Data** for Agentic Postgres and the hackathon
- **Anthropic** for Claude and the Model Context Protocol
- **OpenAI** for GPT models
- **Ollama** for local LLM support
- The open-source community

---

## ðŸ“ž Support

- **Documentation**: [docs/](docs/)
- **Issues**: [GitHub Issues](https://github.com/yourusername/neurobase/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/neurobase/discussions)
- **Email**: support@neurobase.dev

---

## ðŸŒŸ Star Us!

If you find NeuroBase useful, please consider starring the repository!

---

**Built with â¤ï¸ for the Tiger Data Agentic Postgres Challenge**
